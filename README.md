# Rails Generative UI

Add generative UI capabilities to your Ruby on Rails applications. Create dynamic, AI-powered user interfaces that go beyond traditional chatbox interactions using Ollama and ViewComponents.

## What is Generative UI?

Generative UI allows large language models to generate rich, interactive user interface components instead of just text responses. Rather than forcing users to interact solely through a text input field, generative UI dynamically creates appropriate UI elements based on context and user needs.

For example, when a user asks about weather, instead of responding with plain text, the system can generate an interactive weather card with temperature, conditions, and forecasts. When searching for products, it can generate a visual product grid with filters and sorting options.

## Features

- **Tool-based Architecture**: Define tools that map to ViewComponents
- **Ollama Integration**: Support for local and cloud Ollama instances
- **Streaming Support**: Progressive rendering via Turbo Streams
- **Multi-panel Layouts**: Pre-built layouts for rich interfaces
- **Rails Conventions**: Follows Rails patterns and best practices
- **Comprehensive Testing**: RSpec and Cucumber support included
- **Type Safety**: Input validation with dry-schema

## Installation

Add this line to your application's Gemfile:

```ruby
gem 'rails-generative-ui'
```

And then execute:

```bash
bundle install
```

Or install it yourself as:

```bash
gem install rails-generative-ui
```

## Quick Start

### 1. Configure Ollama

Create an initializer at `config/initializers/rails_generative_ui.rb`:

```ruby
RailsGenerativeUi.configure do |config|
  config.ollama_base_url = ENV.fetch("OLLAMA_BASE_URL", "http://localhost:11434")
  config.default_model = "gemma3"
  config.streaming_enabled = true
  config.timeout = 30
end
```

### 2. Create a Tool

Generate a new tool:

```bash
rails generate rails_generative_ui:tool Weather
```

This creates `app/generative_ui/tools/weather_tool.rb`:

```ruby
class WeatherTool < RailsGenerativeUi::Tools::Tool
  description "Display weather information for a location"
  
  input_schema do
    required(:location).filled(:string)
  end
  
  component WeatherComponent
  
  def execute
    # Fetch weather data (example)
    {
      temperature: 72,
      condition: "Sunny",
      location: @params[:location]
    }
  end
end
```

### 3. Create a ViewComponent

Generate the corresponding ViewComponent:

```bash
rails generate component Weather temperature condition location
```

Edit `app/components/weather_component.rb`:

```ruby
class WeatherComponent < ViewComponent::Base
  def initialize(temperature:, condition:, location:)
    @temperature = temperature
    @condition = condition
    @location = location
  end
end
```

And `app/components/weather_component.html.erb`:

```erb
<div class="weather-card">
  <h3><%= @location %></h3>
  <div class="temperature"><%= @temperature %>Â°F</div>
  <div class="condition"><%= @condition %></div>
</div>
```

### 4. Add to Controller

```ruby
class ChatController < ApplicationController
  def create
    respond_to do |format|
      format.turbo_stream do
        generative_ui_stream(
          message: params[:message],
          tools: [WeatherTool]
        )
      end
    end
  end
end
```

### 5. Add to View

```erb
<%= generative_ui_container do %>
  <div id="messages">
    <%= generative_ui_messages(@conversation.messages) %>
  </div>
  
  <%= generative_ui_input(url: chat_path) %>
<% end %>
```

## Architecture

### Core Components

**Tools**: Define what UI components can be generated by the LLM. Each tool specifies its description, input schema, and corresponding ViewComponent.

**Tool Registry**: Manages all registered tools and makes them available to the LLM.

**Ollama Client**: Handles communication with Ollama API, supporting both streaming and non-streaming requests.

**Message Handler**: Orchestrates the flow from user message through LLM processing to UI component rendering.

**Component Renderer**: Maps tool outputs to ViewComponents and renders them.

**Streaming Handler**: Enables progressive rendering via Turbo Streams.

### Data Flow

1. User submits message through input form
2. Controller receives message and calls helper method
3. Message handler adds message to conversation history
4. Ollama client sends request with message and available tools
5. LLM processes request and may invoke tools
6. Tools execute and return structured data
7. Component renderer maps tool outputs to ViewComponents
8. Response is rendered as Turbo Stream updates
9. Client receives and displays components progressively

## Advanced Usage

### Custom Layouts

Create multi-panel layouts:

```erb
<div class="generative-ui-layout">
  <%= generative_ui_panel :context do %>
    <h3>Context</h3>
    <!-- Context information -->
  <% end %>
  
  <%= generative_ui_panel :main do %>
    <div id="messages">
      <%= generative_ui_messages(@conversation.messages) %>
    </div>
  <% end %>
  
  <%= generative_ui_panel :preview do %>
    <h3>Preview</h3>
    <!-- Preview content -->
  <% end %>
</div>
```

### Tool Authorization

Integrate with authorization frameworks:

```ruby
class AdminTool < RailsGenerativeUi::Tools::Tool
  description "Admin-only operations"
  
  def execute
    raise RailsGenerativeUi::ToolError, "Unauthorized" unless current_user.admin?
    
    # Tool logic
  end
end
```

### Complex Tool Schemas

Use dry-schema for complex validation:

```ruby
class ProductSearchTool < RailsGenerativeUi::Tools::Tool
  description "Search for products"
  
  input_schema do
    required(:query).filled(:string)
    optional(:filters).hash do
      optional(:category).filled(:string)
      optional(:min_price).filled(:float)
      optional(:max_price).filled(:float)
      optional(:in_stock).filled(:bool)
    end
    optional(:sort_by).filled(:string)
    optional(:limit).filled(:integer)
  end
  
  component ProductGridComponent
  
  def execute
    # Complex search logic
  end
end
```

### Conversation Management

Access and manage conversations:

```ruby
class ChatController < ApplicationController
  def index
    @conversation = current_generative_ui_conversation
  end
  
  def reset
    reset_generative_ui_conversation!
    redirect_to chat_path
  end
end
```

### Error Handling

Tools should handle errors gracefully:

```ruby
class WeatherTool < RailsGenerativeUi::Tools::Tool
  def execute
    response = fetch_weather(@params[:location])
    
    if response.success?
      parse_weather_data(response)
    else
      raise RailsGenerativeUi::ToolError, "Failed to fetch weather: #{response.error}"
    end
  rescue StandardError => e
    Rails.logger.error "Weather tool error: #{e.message}"
    raise RailsGenerativeUi::ToolError, "Weather service unavailable"
  end
end
```

## Testing

### RSpec

Test tools in isolation:

```ruby
RSpec.describe WeatherTool do
  describe "#execute" do
    it "returns weather data" do
      tool = described_class.new(location: "San Francisco")
      result = tool.execute
      
      expect(result).to include(
        temperature: be_a(Integer),
        condition: be_a(String),
        location: "San Francisco"
      )
    end
  end
end
```

### Cucumber

Test user-facing behavior:

```gherkin
Scenario: User requests weather information
  Given I am on the chat page
  When I type "What's the weather in San Francisco?"
  And I press "Send"
  Then I should see a weather component
  And the weather component should show "San Francisco"
```

## Configuration Options

```ruby
RailsGenerativeUi.configure do |config|
  # Ollama connection
  config.ollama_base_url = "http://localhost:11434"  # Base URL for Ollama
  config.api_key = nil                               # Optional API key for cloud
  
  # Model settings
  config.default_model = "gemma3"                    # Default model to use
  
  # Streaming
  config.streaming_enabled = true                    # Enable streaming responses
  
  # Timeouts and retries
  config.timeout = 30                                # Request timeout in seconds
  config.max_retries = 3                             # Maximum retry attempts
  config.retry_delay = 1                             # Delay between retries
end
```

## Environment Variables

- `OLLAMA_BASE_URL`: Base URL for Ollama (default: http://localhost:11434)
- `OLLAMA_DEFAULT_MODEL`: Default model to use (default: gemma3)
- `OLLAMA_API_KEY`: Optional API key for cloud Ollama

## Requirements

- Ruby >= 3.3.0
- Rails >= 7.0
- ViewComponent >= 3.0
- Turbo Rails >= 1.0
- Ollama (local or cloud)

## Development

After checking out the repo, run `bin/setup` to install dependencies. Then, run `rake spec` to run the tests. You can also run `bin/console` for an interactive prompt.

To install this gem onto your local machine, run `bundle exec rake install`.

## Contributing

Bug reports and pull requests are welcome on GitHub at https://github.com/example/rails-generative-ui.

## License

The gem is available as open source under the terms of the [MIT License](https://opensource.org/licenses/MIT).

## Credits

Inspired by:
- [Vercel AI SDK](https://sdk.vercel.ai/) - Generative UI patterns
- [Ollama](https://ollama.com/) - Local LLM platform
- [ViewComponent](https://viewcomponent.org/) - Rails component framework

## Resources

- [Documentation](https://github.com/example/rails-generative-ui/wiki)
- [API Reference](https://rubydoc.info/gems/rails-generative-ui)
- [Example Application](https://github.com/example/rails-generative-ui-example)
- [Ollama Documentation](https://docs.ollama.com/)
- [Generative UI Article](https://pub.towardsai.net/working-in-a-chatbox-was-a-mistake-and-generative-ui-is-the-antidote-1890bac7cfb5)
